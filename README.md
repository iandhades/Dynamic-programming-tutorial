# Dynamic-programming-tutorial

Dynamic programming is an approach for a complicated problem by breaking it down into a collection of subproblems. Solving each subproblem then storing its solution. When the same subproblems occurs it reuse the previous computed solution. Therefore, it saves computation time and storage space. The method of reusing previously calculated answer is called “memoization”
						
Dynamic programming algorithms are mostly used for optimization, which examines the previously solved subproblems and combine their solution to find out the best solution. In contrast, greedy approach which has the same sequence as dynamic programming but it only picks the locally optimal answers at each step. Greedy approach doesn’t guarantee optimal solution and sometimes it generates unsatisfy answer. Some approaches used greedy approach such as Kruskal’s and Prim’s are proved to generate optimal solution.
						
For example, finding the minimum number of coins to make a given amount. By using dynamic programming, it would firstly finds an optimal solution for each smaller amount then using these solutions to construct an large amount. In comparison, greedy approach will start finding the largest possible coin of a given coin sequence, then using the given amount minus the largest possible coin. For instance the given coin sequence is 1,4,5,15,20 and given amount is 23, the greedy approach will find 20+1+1+1, while the optimal solution is 15 +4 +4.
